{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'one_to_one_dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split(' ')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = ' ' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '\"': 2, \"'\": 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, ':': 9, ';': 10, '<': 11, '=': 12, '>': 13, '?': 14, '[': 15, ']': 16, '{': 17, '|': 18, '}': 19, '¬': 20, 'ঁ': 21, 'ং': 22, 'ঃ': 23, 'অ': 24, 'আ': 25, 'ই': 26, 'ঈ': 27, 'উ': 28, 'ঊ': 29, 'ঋ': 30, 'এ': 31, 'ঐ': 32, 'ও': 33, 'ঔ': 34, 'ক': 35, 'খ': 36, 'গ': 37, 'ঘ': 38, 'ঙ': 39, 'চ': 40, 'ছ': 41, 'জ': 42, 'ঝ': 43, 'ঞ': 44, 'ট': 45, 'ঠ': 46, 'ড': 47, 'ঢ': 48, 'ণ': 49, 'ত': 50, 'থ': 51, 'দ': 52, 'ধ': 53, 'ন': 54, 'প': 55, 'ফ': 56, 'ব': 57, 'ভ': 58, 'ম': 59, 'য': 60, 'র': 61, 'ল': 62, 'শ': 63, 'ষ': 64, 'স': 65, 'হ': 66, 'া': 67, 'ি': 68, 'ী': 69, 'ু': 70, 'ূ': 71, 'ৃ': 72, 'ে': 73, 'ৈ': 74, 'ো': 75, 'ৌ': 76, '্': 77, 'ৎ': 78, 'ড়': 79, 'ঢ়': 80, 'য়': 81, '০': 82, '১': 83, '২': 84, '৩': 85, '৪': 86, '৫': 87, '৬': 88, '৭': 89, '৮': 90, '৯': 91, '\\u200c': 92, '\\u200d': 93, '\\u200f': 94, '—': 95, '’': 96}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('important_data.txt') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "    input_token_index=data['input_index']\n",
    "    target_token_index=data['target_index']\n",
    "    print(input_token_index)\n",
    "    for p in data['input_output']: \n",
    "        num_encoder_tokens = p['num_encoder_tokens']\n",
    "        num_decoder_tokens = p['num_decoder_tokens']\n",
    "        max_encoder_seq_length = p['max_encoder_seq_length']\n",
    "        max_decoder_seq_length = p['max_decoder_seq_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique input tokens: 97\n",
      "Number of unique output tokens: 99\n",
      "Max sequence length for inputs: 22\n",
      "Max sequence length for outputs: 21\n",
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, \"'\": 5, '(': 6, ')': 7, ',': 8, '-': 9, '.': 10, ':': 11, ';': 12, '<': 13, '=': 14, '>': 15, '?': 16, '[': 17, ']': 18, '{': 19, '|': 20, '}': 21, '¬': 22, 'ঁ': 23, 'ং': 24, 'ঃ': 25, 'অ': 26, 'আ': 27, 'ই': 28, 'ঈ': 29, 'উ': 30, 'ঊ': 31, 'ঋ': 32, 'এ': 33, 'ঐ': 34, 'ও': 35, 'ঔ': 36, 'ক': 37, 'খ': 38, 'গ': 39, 'ঘ': 40, 'ঙ': 41, 'চ': 42, 'ছ': 43, 'জ': 44, 'ঝ': 45, 'ঞ': 46, 'ট': 47, 'ঠ': 48, 'ড': 49, 'ঢ': 50, 'ণ': 51, 'ত': 52, 'থ': 53, 'দ': 54, 'ধ': 55, 'ন': 56, 'প': 57, 'ফ': 58, 'ব': 59, 'ভ': 60, 'ম': 61, 'য': 62, 'র': 63, 'ল': 64, 'শ': 65, 'ষ': 66, 'স': 67, 'হ': 68, 'া': 69, 'ি': 70, 'ী': 71, 'ু': 72, 'ূ': 73, 'ৃ': 74, 'ে': 75, 'ৈ': 76, 'ো': 77, 'ৌ': 78, '্': 79, 'ৎ': 80, 'ড়': 81, 'ঢ়': 82, 'য়': 83, '০': 84, '১': 85, '২': 86, '৩': 87, '৪': 88, '৫': 89, '৬': 90, '৭': 91, '৮': 92, '৯': 93, '\\u200c': 94, '\\u200d': 95, '\\u200f': 96, '—': 97, '’': 98}\n"
     ]
    }
   ],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "#num_encoder_tokens = len(input_characters)\n",
    "#num_decoder_tokens = len(target_characters)\n",
    "#max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "#max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "#print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "#input_token_index = dict(\n",
    "#    [(char, i) for i, char in enumerate(input_characters)])\n",
    "#target_token_index = dict(\n",
    "  #  [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "print(target_token_index)\n",
    "\n",
    "#encoder_input_data = np.zeros(\n",
    "   # (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "  #  dtype='float32')\n",
    "\n",
    "#for i, input_text in enumerate(input_texts):\n",
    " #   for t, char in enumerate(input_text):\n",
    "  #      encoder_input_data[i, t, input_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: প্রেমাদাসার\n",
      "Decoded sentence: প্রেমাদাস\n",
      "\n",
      "Input sentence: মাঠ\n",
      "Decoded sentence: মাঠ\n",
      "\n",
      "Input sentence: থেকে\n",
      "Decoded sentence: থেকে\n",
      "\n",
      "Input sentence: শুরু\n",
      "Decoded sentence: শুরু\n",
      "\n",
      "Input sentence: করে\n",
      "Decoded sentence: কর\n",
      "\n",
      "Input sentence: সামাজিক\n",
      "Decoded sentence: সামাজি\n",
      "\n",
      "Input sentence: যোগাযোগমাধ্যম\n",
      "Decoded sentence: যোযাগর্যাম\n",
      "\n",
      "Input sentence: সবখানেই\n",
      "Decoded sentence: জবানেথ\n",
      "\n",
      "Input sentence: চলছে\n",
      "Decoded sentence: চল\n",
      "\n",
      "Input sentence: নাগিন\n",
      "Decoded sentence: নাউনি\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: কাল\n",
      "Decoded sentence: কাল\n",
      "\n",
      "Input sentence: রাতে\n",
      "Decoded sentence: রাতে\n",
      "\n",
      "Input sentence: শ্রীলঙ্কার\n",
      "Decoded sentence: শ্রীল্কার\n",
      "\n",
      "Input sentence: বিপক্ষে\n",
      "Decoded sentence: বিপ্রেক\n",
      "\n",
      "Input sentence: অবিস্মরণীয়\n",
      "Decoded sentence: অবিস্মীত\n",
      "\n",
      "Input sentence: সেই\n",
      "Decoded sentence: সেই\n",
      "\n",
      "Input sentence: জয়ের\n",
      "Decoded sentence: জয়\n",
      "\n",
      "Input sentence: পর\n",
      "Decoded sentence: পরি\n",
      "\n",
      "Input sentence: মাঠেই\n",
      "Decoded sentence: মাঠেই\n",
      "\n",
      "Input sentence: নাগিন\n",
      "Decoded sentence: নাউনি\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: নেচেছেন\n",
      "Decoded sentence: নেনেটি\n",
      "\n",
      "Input sentence: বাংলাদেশ\n",
      "Decoded sentence: বাংলাদেশ\n",
      "\n",
      "Input sentence: দলের\n",
      "Decoded sentence: দল\n",
      "\n",
      "Input sentence: খেলোয়াড়\n",
      "Decoded sentence: খেলো\n",
      "\n",
      "Input sentence: থেকে\n",
      "Decoded sentence: থেকে\n",
      "\n",
      "Input sentence: টিম\n",
      "Decoded sentence: টিমি\n",
      "\n",
      "Input sentence: ম্যানেজমেন্টের\n",
      "Decoded sentence: ম্যানেমিন\n",
      "\n",
      "Input sentence: অনেকে\n",
      "Decoded sentence: অনেকে\n",
      "\n",
      "Input sentence: খেলোয়াড়দের\n",
      "Decoded sentence: খেলোখা\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: সংক্রমিত\n",
      "Decoded sentence: সংক্রমিক\n",
      "\n",
      "Input sentence: হয়েছে\n",
      "Decoded sentence: হে\n",
      "\n",
      "Input sentence: দেশের\n",
      "Decoded sentence: দেশ\n",
      "\n",
      "Input sentence: ক্রিকেটপ্রেমীদের\n",
      "Decoded sentence: ক্রিক্ট\n",
      "\n",
      "Input sentence: মধ্যেও\n",
      "Decoded sentence: মধ্য\n",
      "\n",
      "Input sentence: যে\n",
      "Decoded sentence: গেই\n",
      "\n",
      "Input sentence: যাঁর\n",
      "Decoded sentence: যাঁ\n",
      "\n",
      "Input sentence: মতো\n",
      "Decoded sentence: মতো\n",
      "\n",
      "Input sentence: করে\n",
      "Decoded sentence: কর\n",
      "\n",
      "Input sentence: নাগিন\n",
      "Decoded sentence: নাউনি\n",
      "\n",
      "Input sentence: নাচের\n",
      "Decoded sentence: নাইচ\n",
      "\n",
      "Input sentence: ছবি\n",
      "Decoded sentence: খবি\n",
      "\n",
      "Input sentence: পোস্ট\n",
      "Decoded sentence: পোস্ট\n",
      "\n",
      "Input sentence: করেছেন\n",
      "Decoded sentence: কেন\n",
      "\n",
      "Input sentence: সামাজিক\n",
      "Decoded sentence: সামাজি\n",
      "\n",
      "Input sentence: যোগাযোগমাধ্যমে\n",
      "Decoded sentence: যোযাগর্যাম\n",
      "\n",
      "Input sentence: এমনকি\n",
      "Decoded sentence: এমনি\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: বিশ্ব\n",
      "Decoded sentence: বিশ্ব\n",
      "\n",
      "Input sentence: মিডিয়ার\n",
      "Decoded sentence: মিিয়া\n",
      "\n",
      "Input sentence: নজরেও\n",
      "Decoded sentence: নজ\n",
      "\n",
      "Input sentence: পড়েছে\n",
      "Decoded sentence: পড়ে\n",
      "\n",
      "Input sentence: কিন্তু\n",
      "Decoded sentence: কিন্তু\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাগিন\n",
      "Decoded sentence: নাউনি\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: এর\n",
      "Decoded sentence: এর\n",
      "\n",
      "Input sentence: জনক\n",
      "Decoded sentence: জন\n",
      "\n",
      "Input sentence: কে\n",
      "Decoded sentence: কেপ\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: নেচে\n",
      "Decoded sentence: নেই\n",
      "\n",
      "Input sentence: মুশফিকুর\n",
      "Decoded sentence: মুশিকরি\n",
      "\n",
      "Input sentence: রহিম\n",
      "Decoded sentence: রিহম\n",
      "\n",
      "Input sentence: বিখ্যাত\n",
      "Decoded sentence: বিত্যা\n",
      "\n",
      "Input sentence: হলেও\n",
      "Decoded sentence: হল\n",
      "\n",
      "Input sentence: এটি\n",
      "Decoded sentence: এটি\n",
      "\n",
      "Input sentence: আসলে\n",
      "Decoded sentence: আলেস\n",
      "\n",
      "Input sentence: নাজমুল\n",
      "Decoded sentence: নামিল\n",
      "\n",
      "Input sentence: ইসলামের\n",
      "Decoded sentence: ইসলাম\n",
      "\n",
      "Input sentence: আবিষ্কার\n",
      "Decoded sentence: আবিষ্কার\n",
      "\n",
      "Input sentence: নাজমুল\n",
      "Decoded sentence: নামিল\n",
      "\n",
      "Input sentence: কাল\n",
      "Decoded sentence: কাল\n",
      "\n",
      "Input sentence: বাংলাদেশের\n",
      "Decoded sentence: বাংলাদেশ\n",
      "\n",
      "Input sentence: একাদশে\n",
      "Decoded sentence: একাদেশ\n",
      "\n",
      "Input sentence: ছিলেন\n",
      "Decoded sentence: ছিলিন\n",
      "\n",
      "Input sentence: কিন্তু\n",
      "Decoded sentence: কিন্তু\n",
      "\n",
      "Input sentence: কোনো\n",
      "Decoded sentence: কোনো\n",
      "\n",
      "Input sentence: একটা\n",
      "Decoded sentence: এক\n",
      "\n",
      "Input sentence: কারণে\n",
      "Decoded sentence: কারণ\n",
      "\n",
      "Input sentence: তাঁকে\n",
      "Decoded sentence: তাঁক\n",
      "\n",
      "Input sentence: বোলিং\n",
      "Decoded sentence: বোলিং\n",
      "\n",
      "Input sentence: দেননি\n",
      "Decoded sentence: দেনিন\n",
      "\n",
      "Input sentence: অধিনায়ক\n",
      "Decoded sentence: অধিনা\n",
      "\n",
      "Input sentence: সাকিব\n",
      "Decoded sentence: সাকিব\n",
      "\n",
      "Input sentence: আল\n",
      "Decoded sentence: আল\n",
      "\n",
      "Input sentence: হাসান\n",
      "Decoded sentence: হাসান\n",
      "\n",
      "Input sentence: ফিল্ডিংয়ের\n",
      "Decoded sentence: ফিল্ডিমি\n",
      "\n",
      "Input sentence: সময়\n",
      "Decoded sentence: সময়\n",
      "\n",
      "Input sentence: বেশ\n",
      "Decoded sentence: বেশ\n",
      "\n",
      "Input sentence: কয়েকবারই\n",
      "Decoded sentence: কেভা\n",
      "\n",
      "Input sentence: তাঁর\n",
      "Decoded sentence: তাঁর\n",
      "\n",
      "Input sentence: কাছে\n",
      "Decoded sentence: কাছে\n",
      "\n",
      "Input sentence: বল\n",
      "Decoded sentence: বল\n",
      "\n",
      "Input sentence: গিয়েছিল\n",
      "Decoded sentence: গিি\n",
      "\n",
      "Input sentence: ব্যাটিংয়ে\n",
      "Decoded sentence: ব্যাটিং\n",
      "\n",
      "Input sentence: নামার\n",
      "Decoded sentence: নামার\n",
      "\n",
      "Input sentence: সুযোগ\n",
      "Decoded sentence: সুযোগ\n",
      "\n",
      "Input sentence: পাননি\n",
      "Decoded sentence: পানিন\n",
      "\n",
      "Input sentence: তবে\n",
      "Decoded sentence: তব\n",
      "\n",
      "Input sentence: শেষ\n",
      "Decoded sentence: শেষ\n",
      "\n",
      "Input sentence: ব্যাটসম্যান\n",
      "Decoded sentence: ব্যাসমাট্য\n",
      "\n",
      "Input sentence: হিসেবে\n",
      "Decoded sentence: হিসেব\n",
      "\n",
      "Input sentence: প্যাড\n",
      "Decoded sentence: প্যাড\n",
      "\n",
      "Input sentence: ট্যাড\n",
      "Decoded sentence: ট্যাড\n",
      "\n",
      "Input sentence: পরে\n",
      "Decoded sentence: পরি\n",
      "\n",
      "Input sentence: অপেক্ষাতেই\n",
      "Decoded sentence: উপসেত্রা\n",
      "\n",
      "Input sentence: ছিলেন\n",
      "Decoded sentence: ছিলিন\n",
      "\n",
      "Input sentence: বিপিএলে\n",
      "Decoded sentence: বিপিএল\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: নেচে\n",
      "Decoded sentence: নেই\n",
      "\n",
      "Input sentence: সবার\n",
      "Decoded sentence: সবার\n",
      "\n",
      "Input sentence: দৃষ্টি\n",
      "Decoded sentence: দৃষ্টি\n",
      "\n",
      "Input sentence: কাড়েন\n",
      "Decoded sentence: কাড়েপন\n",
      "\n",
      "Input sentence: নাজমুল\n",
      "Decoded sentence: নামিল\n",
      "\n",
      "Input sentence: সর্বশেষ\n",
      "Decoded sentence: সর্বশেশ\n",
      "\n",
      "Input sentence: বিপিএলে\n",
      "Decoded sentence: বিপিএল\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাগিন\n",
      "Decoded sentence: নাউনি\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: মোটামুটি\n",
      "Decoded sentence: মোটামুটি\n",
      "\n",
      "Input sentence: বিখ্যাত\n",
      "Decoded sentence: বিত্যা\n",
      "\n",
      "Input sentence: বানিয়ে\n",
      "Decoded sentence: বানি\n",
      "\n",
      "Input sentence: দেন\n",
      "Decoded sentence: দেন\n",
      "\n",
      "Input sentence: তিনি\n",
      "Decoded sentence: তিনি\n",
      "\n",
      "Input sentence: উইকেট\n",
      "Decoded sentence: উইকেট\n",
      "\n",
      "Input sentence: পেলেই\n",
      "Decoded sentence: পেলি\n",
      "\n",
      "Input sentence: মাথার\n",
      "Decoded sentence: মাথা\n",
      "\n",
      "Input sentence: ওপর\n",
      "Decoded sentence: ওপি\n",
      "\n",
      "Input sentence: হাত\n",
      "Decoded sentence: হাত\n",
      "\n",
      "Input sentence: তুলে\n",
      "Decoded sentence: তুল\n",
      "\n",
      "Input sentence: সাপের\n",
      "Decoded sentence: সাপ\n",
      "\n",
      "Input sentence: ভঙ্গিতে\n",
      "Decoded sentence: ভ্বেতি\n",
      "\n",
      "Input sentence: এঁকেবেঁকে\n",
      "Decoded sentence: একেবা\n",
      "\n",
      "Input sentence: নাজমুলের\n",
      "Decoded sentence: নাজমুল\n",
      "\n",
      "Input sentence: সেই\n",
      "Decoded sentence: সেই\n",
      "\n",
      "Input sentence: উদ্‌যাপনের\n",
      "Decoded sentence: উদ্যান\n",
      "\n",
      "Input sentence: ভঙ্গিই\n",
      "Decoded sentence: ভ্বি\n",
      "\n",
      "Input sentence: ছড়িয়ে\n",
      "Decoded sentence: ছড়ি\n",
      "\n",
      "Input sentence: পড়েছে\n",
      "Decoded sentence: পড়ে\n",
      "\n",
      "Input sentence: বাংলাদেশ\n",
      "Decoded sentence: বাংলাদেশ\n",
      "\n",
      "Input sentence: দলে\n",
      "Decoded sentence: দল\n",
      "\n",
      "Input sentence: গত\n",
      "Decoded sentence: গত\n",
      "\n",
      "Input sentence: বিপিএলেই\n",
      "Decoded sentence: বিপিএল\n",
      "\n",
      "Input sentence: সংবাদকর্মীরা\n",
      "Decoded sentence: সংবাদকর্মী\n",
      "\n",
      "Input sentence: নাজমুলকে\n",
      "Decoded sentence: নাজমুল\n",
      "\n",
      "Input sentence: প্রশ্ন\n",
      "Decoded sentence: প্রশ্রন\n",
      "\n",
      "Input sentence: করেছিলেন\n",
      "Decoded sentence: কেরি\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাচের\n",
      "Decoded sentence: নাইচ\n",
      "\n",
      "Input sentence: কী\n",
      "Decoded sentence: কা\n",
      "\n",
      "Input sentence: রহস্য\n",
      "Decoded sentence: রহস্য\n",
      "\n",
      "Input sentence: তাঁর\n",
      "Decoded sentence: তাঁর\n",
      "\n",
      "Input sentence: জবাব\n",
      "Decoded sentence: জবাব\n",
      "\n",
      "Input sentence: আগেরবার\n",
      "Decoded sentence: আগেরা\n",
      "\n",
      "Input sentence: রাজশাহী\n",
      "Decoded sentence: রাজশাহী\n",
      "\n",
      "Input sentence: কিংসে\n",
      "Decoded sentence: কিংসি\n",
      "\n",
      "Input sentence: খেলার\n",
      "Decoded sentence: খেলা\n",
      "\n",
      "Input sentence: সময়\n",
      "Decoded sentence: সময়\n",
      "\n",
      "Input sentence: ড্যারেন\n",
      "Decoded sentence: ড্যারেন\n",
      "\n",
      "Input sentence: স্যামিকে\n",
      "Decoded sentence: স্যামি\n",
      "\n",
      "Input sentence: স্নেকগিরি\n",
      "Decoded sentence: স্নেকি\n",
      "\n",
      "Input sentence: সাপের\n",
      "Decoded sentence: সাপ\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: দেখালে\n",
      "Decoded sentence: দেখাল\n",
      "\n",
      "Input sentence: ভয়\n",
      "Decoded sentence: ভভ\n",
      "\n",
      "Input sentence: পেত\n",
      "Decoded sentence: পেত\n",
      "\n",
      "Input sentence: মজাও\n",
      "Decoded sentence: মজা\n",
      "\n",
      "Input sentence: পেত\n",
      "Decoded sentence: পেত\n",
      "\n",
      "Input sentence: ওর\n",
      "Decoded sentence: ওর\n",
      "\n",
      "Input sentence: কাছ\n",
      "Decoded sentence: কাছ\n",
      "\n",
      "Input sentence: থেকেই\n",
      "Decoded sentence: থেইক\n",
      "\n",
      "Input sentence: শুরু\n",
      "Decoded sentence: শুরু\n",
      "\n",
      "Input sentence: তারপর\n",
      "Decoded sentence: তারপর\n",
      "\n",
      "Input sentence: ম্যাচে\n",
      "Decoded sentence: ম্যাচ\n",
      "\n",
      "Input sentence: করতে\n",
      "Decoded sentence: কর\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: করতে\n",
      "Decoded sentence: কর\n",
      "\n",
      "Input sentence: এখন\n",
      "Decoded sentence: এখন\n",
      "\n",
      "Input sentence: হয়ে\n",
      "Decoded sentence: হে\n",
      "\n",
      "Input sentence: গেছে\n",
      "Decoded sentence: গেছ\n",
      "\n",
      "Input sentence: এভাবেই\n",
      "Decoded sentence: এভাবে\n",
      "\n",
      "Input sentence: আসছে\n",
      "Decoded sentence: আছেদ\n",
      "\n",
      "Input sentence: নাজমুলের\n",
      "Decoded sentence: নাজমুল\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাগিন\n",
      "Decoded sentence: নাউনি\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: ত্রিদেশীয়\n",
      "Decoded sentence: ত্রিদী\n",
      "\n",
      "Input sentence: সিরিজ\n",
      "Decoded sentence: সিরিজ\n",
      "\n",
      "Input sentence: দিয়ে\n",
      "Decoded sentence: দিয়\n",
      "\n",
      "Input sentence: জায়গা\n",
      "Decoded sentence: জাগা\n",
      "\n",
      "Input sentence: করে\n",
      "Decoded sentence: কর\n",
      "\n",
      "Input sentence: নিয়েছে\n",
      "Decoded sentence: নিয়ে\n",
      "\n",
      "Input sentence: আন্তর্জাতিক\n",
      "Decoded sentence: আন্তর্তান\n",
      "\n",
      "Input sentence: মঞ্চে\n",
      "Decoded sentence: মঞ্চ\n",
      "\n",
      "Input sentence: বৈশ্বিক\n",
      "Decoded sentence: বৈশ্বির\n",
      "\n",
      "Input sentence: সংবাদমাধ্যমও\n",
      "Decoded sentence: সংবাদামপ্রতি\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাচকে\n",
      "Decoded sentence: নাচক\n",
      "\n",
      "Input sentence: লুফে\n",
      "Decoded sentence: লুফি\n",
      "\n",
      "Input sentence: নিয়েছে\n",
      "Decoded sentence: নিয়ে\n",
      "\n",
      "Input sentence: তবে\n",
      "Decoded sentence: তব\n",
      "\n",
      "Input sentence: শ্রীলঙ্কা\n",
      "Decoded sentence: শ্রীল্কাহ\n",
      "\n",
      "Input sentence: দলের\n",
      "Decoded sentence: দল\n",
      "\n",
      "Input sentence: সর্বশেষ\n",
      "Decoded sentence: সর্বশেশ\n",
      "\n",
      "Input sentence: বাংলাদেশ\n",
      "Decoded sentence: বাংলাদেশ\n",
      "\n",
      "Input sentence: সফরে\n",
      "Decoded sentence: সফর\n",
      "\n",
      "Input sentence: সিলেটে\n",
      "Decoded sentence: সিলেট\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: দিয়ে\n",
      "Decoded sentence: দিয়\n",
      "\n",
      "Input sentence: উদ্‌যাপন\n",
      "Decoded sentence: উদ্যান\n",
      "\n",
      "Input sentence: সেরেছিলেন\n",
      "Decoded sentence: সেরেজি\n",
      "\n",
      "Input sentence: গুনাতিলকা\n",
      "Decoded sentence: গুনাতিল\n",
      "\n",
      "Input sentence: কিন্তু\n",
      "Decoded sentence: কিন্তু\n",
      "\n",
      "Input sentence: নিদাহাস\n",
      "Decoded sentence: নিতাবাহ\n",
      "\n",
      "Input sentence: ট্রফিতে\n",
      "Decoded sentence: প্রেতি\n",
      "\n",
      "Input sentence: ব্যাপারটা\n",
      "Decoded sentence: ব্যাপারা\n",
      "\n",
      "Input sentence: অন্য\n",
      "Decoded sentence: অন্য\n",
      "\n",
      "Input sentence: মাত্রা\n",
      "Decoded sentence: মাত্রা\n",
      "\n",
      "Input sentence: পেয়েছে\n",
      "Decoded sentence: পেয়ে\n",
      "\n",
      "Input sentence: বাংলাদেশ\n",
      "Decoded sentence: বাংলাদেশ\n",
      "\n",
      "Input sentence: দলের\n",
      "Decoded sentence: দল\n",
      "\n",
      "Input sentence: খেলোয়াড়েরা\n",
      "Decoded sentence: খেলোখা\n",
      "\n",
      "Input sentence: তো\n",
      "Decoded sentence: তো\n",
      "\n",
      "Input sentence: বটেই\n",
      "Decoded sentence: বট\n",
      "\n",
      "Input sentence: শ্রীলঙ্কা\n",
      "Decoded sentence: শ্রীল্কাহ\n",
      "\n",
      "Input sentence: দলের\n",
      "Decoded sentence: দল\n",
      "\n",
      "Input sentence: খেলোয়াড়েরাও\n",
      "Decoded sentence: খেলোা\n",
      "\n",
      "Input sentence: উদ্‌যাপন\n",
      "Decoded sentence: উদ্যান\n",
      "\n",
      "Input sentence: সারতে\n",
      "Decoded sentence: সাতর\n",
      "\n",
      "Input sentence: নাগিন\n",
      "Decoded sentence: নাউনি\n",
      "\n",
      "Input sentence: নাচের\n",
      "Decoded sentence: নাইচ\n",
      "\n",
      "Input sentence: দ্বারস্থ\n",
      "Decoded sentence: দ্বারস্থ\n",
      "\n",
      "Input sentence: হয়েছেন\n",
      "Decoded sentence: হেয়নে\n",
      "\n",
      "Input sentence: শুধু\n",
      "Decoded sentence: শুধু\n",
      "\n",
      "Input sentence: তাই\n",
      "Decoded sentence: তাই\n",
      "\n",
      "Input sentence: নয়\n",
      "Decoded sentence: নয়\n",
      "\n",
      "Input sentence: প্রেমাদাসার\n",
      "Decoded sentence: প্রেমাদাস\n",
      "\n",
      "Input sentence: গ্যালারিতে\n",
      "Decoded sentence: গ্যালারিমি\n",
      "\n",
      "Input sentence: দর্শকদের\n",
      "Decoded sentence: দর্দকর\n",
      "\n",
      "Input sentence: মধ্যেও\n",
      "Decoded sentence: মধ্য\n",
      "\n",
      "Input sentence: সাড়া\n",
      "Decoded sentence: সাড়া\n",
      "\n",
      "Input sentence: ফেলেছে\n",
      "Decoded sentence: ফেলে\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: শ্রীলঙ্কার\n",
      "Decoded sentence: শ্রীল্কার\n",
      "\n",
      "Input sentence: বিপক্ষে\n",
      "Decoded sentence: বিপ্রেক\n",
      "\n",
      "Input sentence: নিজেদের\n",
      "Decoded sentence: নিজেদ\n",
      "\n",
      "Input sentence: প্রথম\n",
      "Decoded sentence: প্রতি\n",
      "\n",
      "Input sentence: ম্যাচটা\n",
      "Decoded sentence: ম্যাটা\n",
      "\n",
      "Input sentence: অবিশ্বাস্য\n",
      "Decoded sentence: অবিশ্বস্য\n",
      "\n",
      "Input sentence: নৈপুণ্যে\n",
      "Decoded sentence: নিপুযুর্ত\n",
      "\n",
      "Input sentence: জেতানোর\n",
      "Decoded sentence: জেতান\n",
      "\n",
      "Input sentence: পর\n",
      "Decoded sentence: পরি\n",
      "\n",
      "Input sentence: মুশফিকের\n",
      "Decoded sentence: মুশিফর\n",
      "\n",
      "Input sentence: সেই\n",
      "Decoded sentence: সেই\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: ভুলে\n",
      "Decoded sentence: ভুল\n",
      "\n",
      "Input sentence: যাওয়া\n",
      "Decoded sentence: যাওয়া\n",
      "\n",
      "Input sentence: অসম্ভব\n",
      "Decoded sentence: অসম্ব\n",
      "\n",
      "Input sentence: কাল\n",
      "Decoded sentence: কাল\n",
      "\n",
      "Input sentence: সেই\n",
      "Decoded sentence: সেই\n",
      "\n",
      "Input sentence: একই\n",
      "Decoded sentence: এক\n",
      "\n",
      "Input sentence: দলের\n",
      "Decoded sentence: দল\n",
      "\n",
      "Input sentence: বিপক্ষে\n",
      "Decoded sentence: বিপ্রেক\n",
      "\n",
      "Input sentence: আরেকটি\n",
      "Decoded sentence: আরেইট\n",
      "\n",
      "Input sentence: অবিস্মরণীয়\n",
      "Decoded sentence: অবিস্মীত\n",
      "\n",
      "Input sentence: জয়\n",
      "Decoded sentence: জগ\n",
      "\n",
      "Input sentence: তুলে\n",
      "Decoded sentence: তুল\n",
      "\n",
      "Input sentence: নেওয়ার\n",
      "Decoded sentence: নেওয়া\n",
      "\n",
      "Input sentence: পর\n",
      "Decoded sentence: পরি\n",
      "\n",
      "Input sentence: নেচেছে\n",
      "Decoded sentence: নেন\n",
      "\n",
      "Input sentence: পুরো\n",
      "Decoded sentence: পুরো\n",
      "\n",
      "Input sentence: দল\n",
      "Decoded sentence: দল\n",
      "\n",
      "Input sentence: নেচেছে\n",
      "Decoded sentence: নেন\n",
      "\n",
      "Input sentence: গোটা\n",
      "Decoded sentence: গোটা\n",
      "\n",
      "Input sentence: বাংলাদেশ\n",
      "Decoded sentence: বাংলাদেশ\n",
      "\n",
      "Input sentence: বাংলাদেশের\n",
      "Decoded sentence: বাংলাদেশ\n",
      "\n",
      "Input sentence: দেখানো\n",
      "Decoded sentence: দেখান\n",
      "\n",
      "Input sentence: এই\n",
      "Decoded sentence: এই\n",
      "\n",
      "Input sentence: নাচ\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: দেখে\n",
      "Decoded sentence: দেখ\n",
      "\n",
      "Input sentence: এখন\n",
      "Decoded sentence: এখন\n",
      "\n",
      "Input sentence: নাচছে\n",
      "Decoded sentence: নাচ\n",
      "\n",
      "Input sentence: গোটা\n",
      "Decoded sentence: গোটা\n",
      "\n",
      "Input sentence: ক্রিকেট\n",
      "Decoded sentence: ক্রিক\n",
      "\n",
      "Input sentence: দুনিয়াই\n",
      "Decoded sentence: দিনা\n",
      "\n",
      "292\n",
      "প্রেমাদাসার\n"
     ]
    }
   ],
   "source": [
    "# Restore the model and construct the encoder and decoder.\n",
    "model = load_model('s2s.h5')\n",
    "\n",
    "encoder_inputs = model.input[0]   # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output   # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]   # input_2\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name='input_3')\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name='input_5')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "# Decodes an input sequence.  Future work should support beam search.\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[' ']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "def get_input_data(test_txt):\n",
    "    #txt = input()\n",
    "    txt=test_txt\n",
    "    \n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(txt), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "    \n",
    "    txt = txt.replace(' ', '')\n",
    "    \n",
    "    for t, char in enumerate(txt):\n",
    "        encoder_input_data[0, t, input_token_index[char]] = 1.\n",
    "        \n",
    "    return encoder_input_data\n",
    "\n",
    "\n",
    "word_list=[]\n",
    "data_path='newspaper(khela).txt'\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    #lines = f.read().split(' ')\n",
    "    for word in f.read().split():\n",
    "        word_list.append(word)\n",
    "    for word in word_list:\n",
    "        input_seq = get_input_data(word)\n",
    "        decoded_sentence = decode_sequence(input_seq)\n",
    "        print('Input sentence:',   word)\n",
    "        print('Decoded sentence:', decoded_sentence)\n",
    "        \n",
    "print(len(word_list))        \n",
    "print(word_list[0])\n",
    "\n",
    "#for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    " #   input_seq = get_input_data(test_input_texts[i])\n",
    " #   input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "  #  decoded_sentence = decode_sequence(input_seq)\n",
    "   # print('-')\n",
    "   # print('Input sentence:', input_texts[seq_index])\n",
    "  #  print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "print(epochs)\n",
    "# Run training\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('test_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kire\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 66 and 63. Shapes are [66,1024] and [63,1024]. for 'Assign_8' (op: 'Assign') with input shapes: [66,1024], [63,1024].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    687\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 66 and 63. Shapes are [66,1024] and [63,1024]. for 'Assign_8' (op: 'Assign') with input shapes: [66,1024], [63,1024].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b006614dc5ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# load weights into new model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loaded model from disk\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[0;32m   2643\u001b[0m                 f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[0;32m   2644\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2645\u001b[1;33m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'close'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m   3164\u001b[0m                              ' elements.')\n\u001b[0;32m   3165\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3166\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2363\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[0;32m   2364\u001b[0m                                                     shape=value.shape)\n\u001b[1;32m-> 2365\u001b[1;33m                 \u001b[0massign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2366\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2367\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking)\u001b[0m\n\u001b[0;32m    592\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     \"\"\"\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m    274\u001b[0m     return gen_state_ops.assign(\n\u001b[0;32m    275\u001b[0m         \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    277\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m     61\u001b[0m         \u001b[1;34m\"Assign\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3160\u001b[0m         op_def=op_def)\n\u001b[0;32m   3161\u001b[0m     self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[1;32m-> 3162\u001b[1;33m                            compute_device=compute_device)\n\u001b[0m\u001b[0;32m   3163\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[1;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3206\u001b[0m     \u001b[1;31m# compute_shapes argument.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3208\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3209\u001b[0m     \u001b[1;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3210\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2425\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2426\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2427\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2398\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2400\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2401\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2402\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2329\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2330\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2332\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 66 and 63. Shapes are [66,1024] and [63,1024]. for 'Assign_8' (op: 'Assign') with input shapes: [66,1024], [63,1024]."
     ]
    }
   ],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "from keras.models import model_from_json\n",
    "\n",
    "data_path = 'fra-eng/fra.txt'\n",
    "print(\"kire\")\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"test_model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "#model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model = load_model('s2s.h5')\n",
    "\n",
    "input_characters=66 #here Number of unique input tokens(characters): 66\n",
    "num_encoder_tokens = 66\n",
    "num_decoder_tokens=67\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[' ']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_input_data(test_txt):\n",
    "    #txt = input()\n",
    "    txt=test_txt\n",
    "    \n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(txt), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "    \n",
    "    txt = txt.replace(' ', '')\n",
    "    \n",
    "    for t, char in enumerate(txt):\n",
    "        encoder_input_data[0, t, input_token_index[char]] = 1.\n",
    "        \n",
    "    return encoder_input_data\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Take one sequence (part of the training set)\n",
    "# for trying out decoding.\n",
    "#input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    test_lines = f.read().split('\\n')\n",
    "\n",
    "test_input_texts=[]\n",
    "test_target_texts=[]\n",
    "for line in test_lines[3000: 3100]:\n",
    "    #print(line)\n",
    "    test_input_text, test_target_text = line.split(' ')\n",
    "    #print(test_input_text)\n",
    "    test_input_texts.append(test_input_text)\n",
    "    test_target_texts.append(test_target_text+'\\n')\n",
    "    \n",
    "#print(test_input_texts)   \n",
    "\n",
    "total_test_input=0\n",
    "total_accuracy=0\n",
    "\n",
    "for i in range(50):\n",
    "    total_test_input=total_test_input+1\n",
    "    input_seq = get_input_data(test_input_texts[i])\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    if (decoded_sentence==test_target_texts[i]):\n",
    "        total_accuracy=total_accuracy+1\n",
    "        #print('hoiche')\n",
    "        \n",
    "    print('Input sentence:',   test_input_texts[i])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    #print(decoded_sentence[6])\n",
    "    print('Target sentence:',  test_target_texts[i])\n",
    "    #print(test_target_texts[i][6])\n",
    "  \n",
    "    \n",
    "print('total_test_input:', total_test_input)\n",
    "print('total_accuracy:', total_accuracy)\n",
    "print('result:', (total_accuracy/total_test_input)*100,'%')\n",
    "\n",
    "#yhat = model.predict(input_seq, verbose=0)\n",
    "#print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
