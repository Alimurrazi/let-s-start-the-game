{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from numpy.random import shuffle\n",
    "import random\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 10  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 3000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'one_to_one_dataset.txt'\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 3000\n",
      "Number of unique input tokens: 60\n",
      "Number of unique output tokens: 62\n",
      "Max sequence length for inputs: 20\n",
      "Max sequence length for outputs: 20\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split(' ')\n",
    "    # We use space(' ') as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = ' ' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, None, 60)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, None, 62)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 256), (None, 324608      input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, None, 256),  326656      input_30[0][0]                   \n",
      "                                                                 lstm_7[0][1]                     \n",
      "                                                                 lstm_7[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 62)     15934       lstm_8[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 667,198\n",
      "Trainable params: 667,198\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/10\n",
      "2400/2400 [==============================] - 39s 16ms/step - loss: 1.2399 - acc: 0.6470 - val_loss: 1.1842 - val_acc: 0.6072\n",
      "Epoch 2/10\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 1.1648 - acc: 0.6947 - val_loss: 1.1155 - val_acc: 0.7133\n",
      "Epoch 3/10\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 1.1272 - acc: 0.7058 - val_loss: 1.1176 - val_acc: 0.7024\n",
      "Epoch 4/10\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 1.0997 - acc: 0.7110 - val_loss: 1.0651 - val_acc: 0.7188\n",
      "Epoch 5/10\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 1.0683 - acc: 0.7182 - val_loss: 1.0348 - val_acc: 0.7286\n",
      "Epoch 6/10\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 1.0419 - acc: 0.7227 - val_loss: 1.0196 - val_acc: 0.7299\n",
      "Epoch 7/10\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 1.0154 - acc: 0.7288 - val_loss: 1.0008 - val_acc: 0.7318\n",
      "Epoch 8/10\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 0.9817 - acc: 0.7360 - val_loss: 0.9577 - val_acc: 0.7429\n",
      "Epoch 9/10\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 0.9478 - acc: 0.7435 - val_loss: 0.9425 - val_acc: 0.7453\n",
      "Epoch 10/10\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 0.9179 - acc: 0.7500 - val_loss: 0.9083 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RANA_CSE\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py:2361: UserWarning: Layer lstm_8 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_7/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_7/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "epochs=10\n",
    "print(epochs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "model.save('s2s_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "অ্যান্ডেজ\n",
      "-\n",
      "Input sentence: অ্যান্ডেজ\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "আলমের\n",
      "-\n",
      "Input sentence: আলমের\n",
      "Decoded sentence: আলাল\n",
      "\n",
      "স্পিনিংয়ের\n",
      "-\n",
      "Input sentence: স্পিনিংয়ের\n",
      "Decoded sentence: পার্টি\n",
      "\n",
      "জোরদারের\n",
      "-\n",
      "Input sentence: জোরদারের\n",
      "Decoded sentence: জাদার\n",
      "\n",
      "ঘড়িতে\n",
      "-\n",
      "Input sentence: ঘড়িতে\n",
      "Decoded sentence: খাল\n",
      "\n",
      "ডেনিমেরও\n",
      "-\n",
      "Input sentence: ডেনিমেরও\n",
      "Decoded sentence: সিমি\n",
      "\n",
      "বেবিট্যাক্সিই\n",
      "-\n",
      "Input sentence: বেবিট্যাক্সিই\n",
      "Decoded sentence: বার্তা\n",
      "\n",
      "বাড়িটিতে\n",
      "-\n",
      "Input sentence: বাড়িটিতে\n",
      "Decoded sentence: বার\n",
      "\n",
      "ইনিংসটিতেই\n",
      "-\n",
      "Input sentence: ইনিংসটিতেই\n",
      "Decoded sentence: সিলি\n",
      "\n",
      "মার্কনিকে\n",
      "-\n",
      "Input sentence: মার্কনিকে\n",
      "Decoded sentence: মান্দার্দা\n",
      "\n",
      "ড্রাইয়ারের\n",
      "-\n",
      "Input sentence: ড্রাইয়ারের\n",
      "Decoded sentence: পার্টি\n",
      "\n",
      "পুরোহিতদের\n",
      "-\n",
      "Input sentence: পুরোহিতদের\n",
      "Decoded sentence: পরি\n",
      "\n",
      "অভিবাসীর\n",
      "-\n",
      "Input sentence: অভিবাসীর\n",
      "Decoded sentence: পপিপি\n",
      "\n",
      "অ্যালামনাইদের\n",
      "-\n",
      "Input sentence: অ্যালামনাইদের\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "সুইসপোস্টের\n",
      "-\n",
      "Input sentence: সুইসপোস্টের\n",
      "Decoded sentence: সিক্টি\n",
      "\n",
      "দেয়ালঘড়ির\n",
      "-\n",
      "Input sentence: দেয়ালঘড়ির\n",
      "Decoded sentence: খার\n",
      "\n",
      "প্রাণরসায়নে\n",
      "-\n",
      "Input sentence: প্রাণরসায়নে\n",
      "Decoded sentence: পর্রি\n",
      "\n",
      "ছক্কাটি\n",
      "-\n",
      "Input sentence: ছক্কাটি\n",
      "Decoded sentence: সিক্টি\n",
      "\n",
      "গানবাজনার\n",
      "-\n",
      "Input sentence: গানবাজনার\n",
      "Decoded sentence: জাদার\n",
      "\n",
      "ঘড়িটা\n",
      "-\n",
      "Input sentence: ঘড়িটা\n",
      "Decoded sentence: খাল\n",
      "\n",
      "ঘড়িটি\n",
      "-\n",
      "Input sentence: ঘড়িটি\n",
      "Decoded sentence: এএল\n",
      "\n",
      "ছক্কাটা\n",
      "-\n",
      "Input sentence: ছক্কাটা\n",
      "Decoded sentence: কান্টি\n",
      "\n",
      "গোবরের\n",
      "-\n",
      "Input sentence: গোবরের\n",
      "Decoded sentence: বার\n",
      "\n",
      "হেরাতে\n",
      "-\n",
      "Input sentence: হেরাতে\n",
      "Decoded sentence: খালা\n",
      "\n",
      "বসুরও\n",
      "-\n",
      "Input sentence: বসুরও\n",
      "Decoded sentence: বার\n",
      "\n",
      "কুপনটি\n",
      "-\n",
      "Input sentence: কুপনটি\n",
      "Decoded sentence: পিপি\n",
      "\n",
      "বসুরই\n",
      "-\n",
      "Input sentence: বসুরই\n",
      "Decoded sentence: বার\n",
      "\n",
      "দলীয়করণকে\n",
      "-\n",
      "Input sentence: দলীয়করণকে\n",
      "Decoded sentence: বার\n",
      "\n",
      "লেওনার্দোর\n",
      "-\n",
      "Input sentence: লেওনার্দোর\n",
      "Decoded sentence: মানাদার\n",
      "\n",
      "ধমকটি\n",
      "-\n",
      "Input sentence: ধমকটি\n",
      "Decoded sentence: পিলি\n",
      "\n",
      "সম্পর্কটাকে\n",
      "-\n",
      "Input sentence: সম্পর্কটাকে\n",
      "Decoded sentence: স্র্টি\n",
      "\n",
      "নির্দেশের\n",
      "-\n",
      "Input sentence: নির্দেশের\n",
      "Decoded sentence: সান্দার\n",
      "\n",
      "লেওনার্দোই\n",
      "-\n",
      "Input sentence: লেওনার্দোই\n",
      "Decoded sentence: মানাদার\n",
      "\n",
      "জল্পনার\n",
      "-\n",
      "Input sentence: জল্পনার\n",
      "Decoded sentence: বার্তা\n",
      "\n",
      "স্পন্সরদের\n",
      "-\n",
      "Input sentence: স্পন্সরদের\n",
      "Decoded sentence: স্রান্তি\n",
      "\n",
      "কোকিলও\n",
      "-\n",
      "Input sentence: কোকিলও\n",
      "Decoded sentence: সিকি\n",
      "\n",
      "ইয়াসমিনের\n",
      "-\n",
      "Input sentence: ইয়াসমিনের\n",
      "Decoded sentence: মিলি\n",
      "\n",
      "রঞ্জনের\n",
      "-\n",
      "Input sentence: রঞ্জনের\n",
      "Decoded sentence: বার্তা\n",
      "\n",
      "বয়াতির\n",
      "-\n",
      "Input sentence: বয়াতির\n",
      "Decoded sentence: বার\n",
      "\n",
      "কবিতাগুচ্ছ\n",
      "-\n",
      "Input sentence: কবিতাগুচ্ছ\n",
      "Decoded sentence: বান্দা\n",
      "\n",
      "অ্যাডফেস্টে\n",
      "-\n",
      "Input sentence: অ্যাডফেস্টে\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "দেনদরবারের\n",
      "-\n",
      "Input sentence: দেনদরবারের\n",
      "Decoded sentence: হাদার\n",
      "\n",
      "হকিংয়ের\n",
      "-\n",
      "Input sentence: হকিংয়ের\n",
      "Decoded sentence: সিল\n",
      "\n",
      "নির্দেশেই\n",
      "-\n",
      "Input sentence: নির্দেশেই\n",
      "Decoded sentence: সান্দার\n",
      "\n",
      "নির্দেশেও\n",
      "-\n",
      "Input sentence: নির্দেশেও\n",
      "Decoded sentence: সান্দার\n",
      "\n",
      "জ্যাজের\n",
      "-\n",
      "Input sentence: জ্যাজের\n",
      "Decoded sentence: ব্র্যান\n",
      "\n",
      "ডাকাতদের\n",
      "-\n",
      "Input sentence: ডাকাতদের\n",
      "Decoded sentence: মানাদা\n",
      "\n",
      "স্মৃতিস্মারকের\n",
      "-\n",
      "Input sentence: স্মৃতিস্মারকের\n",
      "Decoded sentence: ক্র্টি\n",
      "\n",
      "শিবলুকে\n",
      "-\n",
      "Input sentence: শিবলুকে\n",
      "Decoded sentence: পার\n",
      "\n",
      "কম্পিউটিংয়ের\n",
      "-\n",
      "Input sentence: কম্পিউটিংয়ের\n",
      "Decoded sentence: পিক্টি\n",
      "\n",
      "ক্যাশিয়ারের\n",
      "-\n",
      "Input sentence: ক্যাশিয়ারের\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "লেন্সটিকে\n",
      "-\n",
      "Input sentence: লেন্সটিকে\n",
      "Decoded sentence: সান্টি\n",
      "\n",
      "সিমবিয়ানে\n",
      "-\n",
      "Input sentence: সিমবিয়ানে\n",
      "Decoded sentence: সিমিনি\n",
      "\n",
      "খুনে\n",
      "-\n",
      "Input sentence: খুনে\n",
      "Decoded sentence: খাল\n",
      "\n",
      "বার্কের\n",
      "-\n",
      "Input sentence: বার্কের\n",
      "Decoded sentence: বার্দার\n",
      "\n",
      "বাড়িটিকে\n",
      "-\n",
      "Input sentence: বাড়িটিকে\n",
      "Decoded sentence: গোল\n",
      "\n",
      "ইনকরপোরেশনের\n",
      "-\n",
      "Input sentence: ইনকরপোরেশনের\n",
      "Decoded sentence: সাবা\n",
      "\n",
      "খেজুরগুলো\n",
      "-\n",
      "Input sentence: খেজুরগুলো\n",
      "Decoded sentence: খালা\n",
      "\n",
      "বৃদ্ধিতে\n",
      "-\n",
      "Input sentence: বৃদ্ধিতে\n",
      "Decoded sentence: বার্দার\n",
      "\n",
      "খুনই\n",
      "-\n",
      "Input sentence: খুনই\n",
      "Decoded sentence: খাল\n",
      "\n",
      "গল্পটাকে\n",
      "-\n",
      "Input sentence: গল্পটাকে\n",
      "Decoded sentence: পর্রি\n",
      "\n",
      "পরমাণুবিজ্ঞানীর\n",
      "-\n",
      "Input sentence: পরমাণুবিজ্ঞানীর\n",
      "Decoded sentence: পাপি\n",
      "\n",
      "খুনও\n",
      "-\n",
      "Input sentence: খুনও\n",
      "Decoded sentence: খাল\n",
      "\n",
      "কিডনিগুলো\n",
      "-\n",
      "Input sentence: কিডনিগুলো\n",
      "Decoded sentence: সিকি\n",
      "\n",
      "সদরে\n",
      "-\n",
      "Input sentence: সদরে\n",
      "Decoded sentence: বার\n",
      "\n",
      "তৃণভূমির\n",
      "-\n",
      "Input sentence: তৃণভূমির\n",
      "Decoded sentence: শুরু\n",
      "\n",
      "উদ্বাস্তুরা\n",
      "-\n",
      "Input sentence: উদ্বাস্তুরা\n",
      "Decoded sentence: বার্দা\n",
      "\n",
      "ডিকশনারির\n",
      "-\n",
      "Input sentence: ডিকশনারির\n",
      "Decoded sentence: সিকিনি\n",
      "\n",
      "গণ্ডির\n",
      "-\n",
      "Input sentence: গণ্ডির\n",
      "Decoded sentence: পর্রি\n",
      "\n",
      "কিছুরই\n",
      "-\n",
      "Input sentence: কিছুরই\n",
      "Decoded sentence: সিকি\n",
      "\n",
      "ভ্রমণকারীর\n",
      "-\n",
      "Input sentence: ভ্রমণকারীর\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "জ্ঞানকেন্দ্রটি\n",
      "-\n",
      "Input sentence: জ্ঞানকেন্দ্রটি\n",
      "Decoded sentence: বার্যান\n",
      "\n",
      "ভোক্তাদের\n",
      "-\n",
      "Input sentence: ভোক্তাদের\n",
      "Decoded sentence: সান্দা\n",
      "\n",
      "হইলে\n",
      "-\n",
      "Input sentence: হইলে\n",
      "Decoded sentence: খাল\n",
      "\n",
      "হারেছের\n",
      "-\n",
      "Input sentence: হারেছের\n",
      "Decoded sentence: খালা\n",
      "\n",
      "জুটিটার\n",
      "-\n",
      "Input sentence: জুটিটার\n",
      "Decoded sentence: সান\n",
      "\n",
      "বজ্রপাতের\n",
      "-\n",
      "Input sentence: বজ্রপাতের\n",
      "Decoded sentence: বার্দা\n",
      "\n",
      "সাংবাদিকেরা\n",
      "-\n",
      "Input sentence: সাংবাদিকেরা\n",
      "Decoded sentence: জানাদা\n",
      "\n",
      "মামলাজটের\n",
      "-\n",
      "Input sentence: মামলাজটের\n",
      "Decoded sentence: মালান\n",
      "\n",
      "নির্বাপণযন্ত্রও\n",
      "-\n",
      "Input sentence: নির্বাপণযন্ত্রও\n",
      "Decoded sentence: সান্দার\n",
      "\n",
      "আলিঙ্গনের\n",
      "-\n",
      "Input sentence: আলিঙ্গনের\n",
      "Decoded sentence: মানাদার\n",
      "\n",
      "সাজাদপুরের\n",
      "-\n",
      "Input sentence: সাজাদপুরের\n",
      "Decoded sentence: মাতাদার\n",
      "\n",
      "খুবই\n",
      "-\n",
      "Input sentence: খুবই\n",
      "Decoded sentence: খার\n",
      "\n",
      "জুটিটির\n",
      "-\n",
      "Input sentence: জুটিটির\n",
      "Decoded sentence: সিকি\n",
      "\n",
      "পদায়নে\n",
      "-\n",
      "Input sentence: পদায়নে\n",
      "Decoded sentence: পরি\n",
      "\n",
      "পেট্রোলের\n",
      "-\n",
      "Input sentence: পেট্রোলের\n",
      "Decoded sentence: পপিপি\n",
      "\n",
      "হইতে\n",
      "-\n",
      "Input sentence: হইতে\n",
      "Decoded sentence: খাল\n",
      "\n",
      "স্পোর্তোও\n",
      "-\n",
      "Input sentence: স্পোর্তোও\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "এক্সচেঞ্জগুলোর\n",
      "-\n",
      "Input sentence: এক্সচেঞ্জগুলোর\n",
      "Decoded sentence: কান্টি\n",
      "\n",
      "শাখাওয়াতের\n",
      "-\n",
      "Input sentence: শাখাওয়াতের\n",
      "Decoded sentence: বার\n",
      "\n",
      "শরীফকেও\n",
      "-\n",
      "Input sentence: শরীফকেও\n",
      "Decoded sentence: গরি\n",
      "\n",
      "বাস্তুসংস্থানে\n",
      "-\n",
      "Input sentence: বাস্তুসংস্থানে\n",
      "Decoded sentence: বার্দার\n",
      "\n",
      "ছেলেরাই\n",
      "-\n",
      "Input sentence: ছেলেরাই\n",
      "Decoded sentence: আলাল\n",
      "\n",
      "চৌধুরীপাড়ায়\n",
      "-\n",
      "Input sentence: চৌধুরীপাড়ায়\n",
      "Decoded sentence: বারার\n",
      "\n",
      "জুটিটাও\n",
      "-\n",
      "Input sentence: জুটিটাও\n",
      "Decoded sentence: সেল\n",
      "\n",
      "জুটিটাই\n",
      "-\n",
      "Input sentence: জুটিটাই\n",
      "Decoded sentence: সিকা\n",
      "\n",
      "মাত্তেওকে\n",
      "-\n",
      "Input sentence: মাত্তেওকে\n",
      "Decoded sentence: মান্দার্দ\n",
      "\n",
      "ছেলেরাও\n",
      "-\n",
      "Input sentence: ছেলেরাও\n",
      "Decoded sentence: আলাল\n",
      "\n",
      "মাশরুবার\n",
      "-\n",
      "Input sentence: মাশরুবার\n",
      "Decoded sentence: মাতাদার\n",
      "\n",
      "পাকিস্তানিদেরও\n",
      "-\n",
      "Input sentence: পাকিস্তানিদেরও\n",
      "Decoded sentence: পাপিকা\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[' ']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_input_data(test_txt):\n",
    "    #txt = input()\n",
    "    txt=test_txt\n",
    "    \n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(txt), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "    \n",
    "    txt = txt.replace(' ', '')\n",
    "    \n",
    "    for t, char in enumerate(txt):\n",
    "        encoder_input_data[0, t, input_token_index[char]] = 1.\n",
    "        \n",
    "    return encoder_input_data\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Take one sequence (part of the training set)\n",
    "# for trying out decoding.\n",
    "#input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    test_lines = f.read().split('\\n')\n",
    "\n",
    "test_input_texts=[]    \n",
    "for line in test_lines:\n",
    "    #print(line)\n",
    "    test_input_text, test_target_text = line.split(' ')\n",
    "    #print(test_input_text)\n",
    "    test_input_texts.append(test_input_text)\n",
    "    \n",
    "#print(test_input_texts)   \n",
    "    \n",
    "for i in range(100):\n",
    "    input_seq = get_input_data(test_input_texts[i])\n",
    "    print(test_input_texts[i])\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', test_input_texts[i])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 19s 8ms/step - loss: 0.8950 - acc: 0.7546 - val_loss: 0.8879 - val_acc: 0.7596\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 14s 6ms/step - loss: 0.8613 - acc: 0.7611 - val_loss: 0.8732 - val_acc: 0.7616\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 0.8305 - acc: 0.7700 - val_loss: 0.8466 - val_acc: 0.7681\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 0.8015 - acc: 0.7773 - val_loss: 0.8551 - val_acc: 0.7637\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 13s 5ms/step - loss: 0.7775 - acc: 0.7832 - val_loss: 0.8383 - val_acc: 0.7662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RANA_CSE\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py:2361: UserWarning: Layer lstm_8 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_7_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_7_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "#model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "epochs=5\n",
    "print(epochs)\n",
    "model = load_model('s2s_test.h5')\n",
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "model.save('s2s_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RANA_CSE\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py:2361: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_3_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save('s2s_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "অ্যান্ডেজ\n",
      "-\n",
      "Input sentence: অ্যান্ডেজ\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "আলমের\n",
      "-\n",
      "Input sentence: আলমের\n",
      "Decoded sentence: আলাল\n",
      "\n",
      "স্পিনিংয়ের\n",
      "-\n",
      "Input sentence: স্পিনিংয়ের\n",
      "Decoded sentence: পার্টি\n",
      "\n",
      "জোরদারের\n",
      "-\n",
      "Input sentence: জোরদারের\n",
      "Decoded sentence: জাদার\n",
      "\n",
      "ঘড়িতে\n",
      "-\n",
      "Input sentence: ঘড়িতে\n",
      "Decoded sentence: খাল\n",
      "\n",
      "ডেনিমেরও\n",
      "-\n",
      "Input sentence: ডেনিমেরও\n",
      "Decoded sentence: সিমি\n",
      "\n",
      "বেবিট্যাক্সিই\n",
      "-\n",
      "Input sentence: বেবিট্যাক্সিই\n",
      "Decoded sentence: বার্তা\n",
      "\n",
      "বাড়িটিতে\n",
      "-\n",
      "Input sentence: বাড়িটিতে\n",
      "Decoded sentence: বার\n",
      "\n",
      "ইনিংসটিতেই\n",
      "-\n",
      "Input sentence: ইনিংসটিতেই\n",
      "Decoded sentence: সিলি\n",
      "\n",
      "মার্কনিকে\n",
      "-\n",
      "Input sentence: মার্কনিকে\n",
      "Decoded sentence: মান্দার্দা\n",
      "\n",
      "ড্রাইয়ারের\n",
      "-\n",
      "Input sentence: ড্রাইয়ারের\n",
      "Decoded sentence: পার্টি\n",
      "\n",
      "পুরোহিতদের\n",
      "-\n",
      "Input sentence: পুরোহিতদের\n",
      "Decoded sentence: পরি\n",
      "\n",
      "অভিবাসীর\n",
      "-\n",
      "Input sentence: অভিবাসীর\n",
      "Decoded sentence: পপিপি\n",
      "\n",
      "অ্যালামনাইদের\n",
      "-\n",
      "Input sentence: অ্যালামনাইদের\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "সুইসপোস্টের\n",
      "-\n",
      "Input sentence: সুইসপোস্টের\n",
      "Decoded sentence: সিক্টি\n",
      "\n",
      "দেয়ালঘড়ির\n",
      "-\n",
      "Input sentence: দেয়ালঘড়ির\n",
      "Decoded sentence: খার\n",
      "\n",
      "প্রাণরসায়নে\n",
      "-\n",
      "Input sentence: প্রাণরসায়নে\n",
      "Decoded sentence: পর্রি\n",
      "\n",
      "ছক্কাটি\n",
      "-\n",
      "Input sentence: ছক্কাটি\n",
      "Decoded sentence: সিক্টি\n",
      "\n",
      "গানবাজনার\n",
      "-\n",
      "Input sentence: গানবাজনার\n",
      "Decoded sentence: জাদার\n",
      "\n",
      "ঘড়িটা\n",
      "-\n",
      "Input sentence: ঘড়িটা\n",
      "Decoded sentence: খাল\n",
      "\n",
      "ঘড়িটি\n",
      "-\n",
      "Input sentence: ঘড়িটি\n",
      "Decoded sentence: এএল\n",
      "\n",
      "ছক্কাটা\n",
      "-\n",
      "Input sentence: ছক্কাটা\n",
      "Decoded sentence: কান্টি\n",
      "\n",
      "গোবরের\n",
      "-\n",
      "Input sentence: গোবরের\n",
      "Decoded sentence: বার\n",
      "\n",
      "হেরাতে\n",
      "-\n",
      "Input sentence: হেরাতে\n",
      "Decoded sentence: খালা\n",
      "\n",
      "বসুরও\n",
      "-\n",
      "Input sentence: বসুরও\n",
      "Decoded sentence: বার\n",
      "\n",
      "কুপনটি\n",
      "-\n",
      "Input sentence: কুপনটি\n",
      "Decoded sentence: পিপি\n",
      "\n",
      "বসুরই\n",
      "-\n",
      "Input sentence: বসুরই\n",
      "Decoded sentence: বার\n",
      "\n",
      "দলীয়করণকে\n",
      "-\n",
      "Input sentence: দলীয়করণকে\n",
      "Decoded sentence: বার\n",
      "\n",
      "লেওনার্দোর\n",
      "-\n",
      "Input sentence: লেওনার্দোর\n",
      "Decoded sentence: মানাদার\n",
      "\n",
      "ধমকটি\n",
      "-\n",
      "Input sentence: ধমকটি\n",
      "Decoded sentence: পিলি\n",
      "\n",
      "সম্পর্কটাকে\n",
      "-\n",
      "Input sentence: সম্পর্কটাকে\n",
      "Decoded sentence: স্র্টি\n",
      "\n",
      "নির্দেশের\n",
      "-\n",
      "Input sentence: নির্দেশের\n",
      "Decoded sentence: সান্দার\n",
      "\n",
      "লেওনার্দোই\n",
      "-\n",
      "Input sentence: লেওনার্দোই\n",
      "Decoded sentence: মানাদার\n",
      "\n",
      "জল্পনার\n",
      "-\n",
      "Input sentence: জল্পনার\n",
      "Decoded sentence: বার্তা\n",
      "\n",
      "স্পন্সরদের\n",
      "-\n",
      "Input sentence: স্পন্সরদের\n",
      "Decoded sentence: স্রান্তি\n",
      "\n",
      "কোকিলও\n",
      "-\n",
      "Input sentence: কোকিলও\n",
      "Decoded sentence: সিকি\n",
      "\n",
      "ইয়াসমিনের\n",
      "-\n",
      "Input sentence: ইয়াসমিনের\n",
      "Decoded sentence: মিলি\n",
      "\n",
      "রঞ্জনের\n",
      "-\n",
      "Input sentence: রঞ্জনের\n",
      "Decoded sentence: বার্তা\n",
      "\n",
      "বয়াতির\n",
      "-\n",
      "Input sentence: বয়াতির\n",
      "Decoded sentence: বার\n",
      "\n",
      "কবিতাগুচ্ছ\n",
      "-\n",
      "Input sentence: কবিতাগুচ্ছ\n",
      "Decoded sentence: বান্দা\n",
      "\n",
      "অ্যাডফেস্টে\n",
      "-\n",
      "Input sentence: অ্যাডফেস্টে\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "দেনদরবারের\n",
      "-\n",
      "Input sentence: দেনদরবারের\n",
      "Decoded sentence: হাদার\n",
      "\n",
      "হকিংয়ের\n",
      "-\n",
      "Input sentence: হকিংয়ের\n",
      "Decoded sentence: সিল\n",
      "\n",
      "নির্দেশেই\n",
      "-\n",
      "Input sentence: নির্দেশেই\n",
      "Decoded sentence: সান্দার\n",
      "\n",
      "নির্দেশেও\n",
      "-\n",
      "Input sentence: নির্দেশেও\n",
      "Decoded sentence: সান্দার\n",
      "\n",
      "জ্যাজের\n",
      "-\n",
      "Input sentence: জ্যাজের\n",
      "Decoded sentence: ব্র্যান\n",
      "\n",
      "ডাকাতদের\n",
      "-\n",
      "Input sentence: ডাকাতদের\n",
      "Decoded sentence: মানাদা\n",
      "\n",
      "স্মৃতিস্মারকের\n",
      "-\n",
      "Input sentence: স্মৃতিস্মারকের\n",
      "Decoded sentence: ক্র্টি\n",
      "\n",
      "শিবলুকে\n",
      "-\n",
      "Input sentence: শিবলুকে\n",
      "Decoded sentence: পার\n",
      "\n",
      "কম্পিউটিংয়ের\n",
      "-\n",
      "Input sentence: কম্পিউটিংয়ের\n",
      "Decoded sentence: পিক্টি\n",
      "\n",
      "ক্যাশিয়ারের\n",
      "-\n",
      "Input sentence: ক্যাশিয়ারের\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "লেন্সটিকে\n",
      "-\n",
      "Input sentence: লেন্সটিকে\n",
      "Decoded sentence: সান্টি\n",
      "\n",
      "সিমবিয়ানে\n",
      "-\n",
      "Input sentence: সিমবিয়ানে\n",
      "Decoded sentence: সিমিনি\n",
      "\n",
      "খুনে\n",
      "-\n",
      "Input sentence: খুনে\n",
      "Decoded sentence: খাল\n",
      "\n",
      "বার্কের\n",
      "-\n",
      "Input sentence: বার্কের\n",
      "Decoded sentence: বার্দার\n",
      "\n",
      "বাড়িটিকে\n",
      "-\n",
      "Input sentence: বাড়িটিকে\n",
      "Decoded sentence: গোল\n",
      "\n",
      "ইনকরপোরেশনের\n",
      "-\n",
      "Input sentence: ইনকরপোরেশনের\n",
      "Decoded sentence: সাবা\n",
      "\n",
      "খেজুরগুলো\n",
      "-\n",
      "Input sentence: খেজুরগুলো\n",
      "Decoded sentence: খালা\n",
      "\n",
      "বৃদ্ধিতে\n",
      "-\n",
      "Input sentence: বৃদ্ধিতে\n",
      "Decoded sentence: বার্দার\n",
      "\n",
      "খুনই\n",
      "-\n",
      "Input sentence: খুনই\n",
      "Decoded sentence: খাল\n",
      "\n",
      "গল্পটাকে\n",
      "-\n",
      "Input sentence: গল্পটাকে\n",
      "Decoded sentence: পর্রি\n",
      "\n",
      "পরমাণুবিজ্ঞানীর\n",
      "-\n",
      "Input sentence: পরমাণুবিজ্ঞানীর\n",
      "Decoded sentence: পাপি\n",
      "\n",
      "খুনও\n",
      "-\n",
      "Input sentence: খুনও\n",
      "Decoded sentence: খাল\n",
      "\n",
      "কিডনিগুলো\n",
      "-\n",
      "Input sentence: কিডনিগুলো\n",
      "Decoded sentence: সিকি\n",
      "\n",
      "সদরে\n",
      "-\n",
      "Input sentence: সদরে\n",
      "Decoded sentence: বার\n",
      "\n",
      "তৃণভূমির\n",
      "-\n",
      "Input sentence: তৃণভূমির\n",
      "Decoded sentence: শুরু\n",
      "\n",
      "উদ্বাস্তুরা\n",
      "-\n",
      "Input sentence: উদ্বাস্তুরা\n",
      "Decoded sentence: বার্দা\n",
      "\n",
      "ডিকশনারির\n",
      "-\n",
      "Input sentence: ডিকশনারির\n",
      "Decoded sentence: সিকিনি\n",
      "\n",
      "গণ্ডির\n",
      "-\n",
      "Input sentence: গণ্ডির\n",
      "Decoded sentence: পর্রি\n",
      "\n",
      "কিছুরই\n",
      "-\n",
      "Input sentence: কিছুরই\n",
      "Decoded sentence: সিকি\n",
      "\n",
      "ভ্রমণকারীর\n",
      "-\n",
      "Input sentence: ভ্রমণকারীর\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "জ্ঞানকেন্দ্রটি\n",
      "-\n",
      "Input sentence: জ্ঞানকেন্দ্রটি\n",
      "Decoded sentence: বার্যান\n",
      "\n",
      "ভোক্তাদের\n",
      "-\n",
      "Input sentence: ভোক্তাদের\n",
      "Decoded sentence: সান্দা\n",
      "\n",
      "হইলে\n",
      "-\n",
      "Input sentence: হইলে\n",
      "Decoded sentence: খাল\n",
      "\n",
      "হারেছের\n",
      "-\n",
      "Input sentence: হারেছের\n",
      "Decoded sentence: খালা\n",
      "\n",
      "জুটিটার\n",
      "-\n",
      "Input sentence: জুটিটার\n",
      "Decoded sentence: সান\n",
      "\n",
      "বজ্রপাতের\n",
      "-\n",
      "Input sentence: বজ্রপাতের\n",
      "Decoded sentence: বার্দা\n",
      "\n",
      "সাংবাদিকেরা\n",
      "-\n",
      "Input sentence: সাংবাদিকেরা\n",
      "Decoded sentence: জানাদা\n",
      "\n",
      "মামলাজটের\n",
      "-\n",
      "Input sentence: মামলাজটের\n",
      "Decoded sentence: মালান\n",
      "\n",
      "নির্বাপণযন্ত্রও\n",
      "-\n",
      "Input sentence: নির্বাপণযন্ত্রও\n",
      "Decoded sentence: সান্দার\n",
      "\n",
      "আলিঙ্গনের\n",
      "-\n",
      "Input sentence: আলিঙ্গনের\n",
      "Decoded sentence: মানাদার\n",
      "\n",
      "সাজাদপুরের\n",
      "-\n",
      "Input sentence: সাজাদপুরের\n",
      "Decoded sentence: মাতাদার\n",
      "\n",
      "খুবই\n",
      "-\n",
      "Input sentence: খুবই\n",
      "Decoded sentence: খার\n",
      "\n",
      "জুটিটির\n",
      "-\n",
      "Input sentence: জুটিটির\n",
      "Decoded sentence: সিকি\n",
      "\n",
      "পদায়নে\n",
      "-\n",
      "Input sentence: পদায়নে\n",
      "Decoded sentence: পরি\n",
      "\n",
      "পেট্রোলের\n",
      "-\n",
      "Input sentence: পেট্রোলের\n",
      "Decoded sentence: পপিপি\n",
      "\n",
      "হইতে\n",
      "-\n",
      "Input sentence: হইতে\n",
      "Decoded sentence: খাল\n",
      "\n",
      "স্পোর্তোও\n",
      "-\n",
      "Input sentence: স্পোর্তোও\n",
      "Decoded sentence: প্রান্তি\n",
      "\n",
      "এক্সচেঞ্জগুলোর\n",
      "-\n",
      "Input sentence: এক্সচেঞ্জগুলোর\n",
      "Decoded sentence: কান্টি\n",
      "\n",
      "শাখাওয়াতের\n",
      "-\n",
      "Input sentence: শাখাওয়াতের\n",
      "Decoded sentence: বার\n",
      "\n",
      "শরীফকেও\n",
      "-\n",
      "Input sentence: শরীফকেও\n",
      "Decoded sentence: গরি\n",
      "\n",
      "বাস্তুসংস্থানে\n",
      "-\n",
      "Input sentence: বাস্তুসংস্থানে\n",
      "Decoded sentence: বার্দার\n",
      "\n",
      "ছেলেরাই\n",
      "-\n",
      "Input sentence: ছেলেরাই\n",
      "Decoded sentence: আলাল\n",
      "\n",
      "চৌধুরীপাড়ায়\n",
      "-\n",
      "Input sentence: চৌধুরীপাড়ায়\n",
      "Decoded sentence: বারার\n",
      "\n",
      "জুটিটাও\n",
      "-\n",
      "Input sentence: জুটিটাও\n",
      "Decoded sentence: সেল\n",
      "\n",
      "জুটিটাই\n",
      "-\n",
      "Input sentence: জুটিটাই\n",
      "Decoded sentence: সিকা\n",
      "\n",
      "মাত্তেওকে\n",
      "-\n",
      "Input sentence: মাত্তেওকে\n",
      "Decoded sentence: মান্দার্দ\n",
      "\n",
      "ছেলেরাও\n",
      "-\n",
      "Input sentence: ছেলেরাও\n",
      "Decoded sentence: আলাল\n",
      "\n",
      "মাশরুবার\n",
      "-\n",
      "Input sentence: মাশরুবার\n",
      "Decoded sentence: মাতাদার\n",
      "\n",
      "পাকিস্তানিদেরও\n",
      "-\n",
      "Input sentence: পাকিস্তানিদেরও\n",
      "Decoded sentence: পাপিকা\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[' ']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_input_data(test_txt):\n",
    "    #txt = input()\n",
    "    txt=test_txt\n",
    "    \n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(txt), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "    \n",
    "    txt = txt.replace(' ', '')\n",
    "    \n",
    "    for t, char in enumerate(txt):\n",
    "        encoder_input_data[0, t, input_token_index[char]] = 1.\n",
    "        \n",
    "    return encoder_input_data\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Take one sequence (part of the training set)\n",
    "# for trying out decoding.\n",
    "#input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    test_lines = f.read().split('\\n')\n",
    "\n",
    "test_input_texts=[]    \n",
    "for line in test_lines:\n",
    "    #print(line)\n",
    "    test_input_text, test_target_text = line.split(' ')\n",
    "    #print(test_input_text)\n",
    "    test_input_texts.append(test_input_text)\n",
    "    \n",
    "#print(test_input_texts)   \n",
    "    \n",
    "for i in range(100):\n",
    "    input_seq = get_input_data(test_input_texts[i])\n",
    "    print(test_input_texts[i])\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', test_input_texts[i])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6e0bf45ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6e0c85b278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1000\n",
      "Number of unique input tokens: 56\n",
      "Number of unique output tokens: 58\n",
      "Max sequence length for inputs: 22\n",
      "Max sequence length for outputs: 22\n",
      "[[[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  1.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "    0.  0.]]]\n",
      "before\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_1 to have shape (None, 66) but got array with shape (22, 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a6cceebf108c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtest_input_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_encoder_input_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mtest_decoded_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input sentence:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_input_texts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-40264f2b423d>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Encode the input as state vectors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"before\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mstates_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"after\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1780\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1781\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1782\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1783\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    118\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected input_1 to have shape (None, 66) but got array with shape (22, 56)"
     ]
    }
   ],
   "source": [
    "#for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    " #   input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    " #   decoded_sentence = decode_sequence(input_seq)\n",
    "  #  print('-')\n",
    "   # print('Input sentence:', input_texts[seq_index])\n",
    "   # print('Decoded sentence:', decoded_sentence)\n",
    "    \n",
    "# Vectorize the data.\n",
    "test_input_texts = []\n",
    "test_target_texts = []\n",
    "test_input_characters = set()\n",
    "test_target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    test_lines = f.read().split('\\n')\n",
    "for line in test_lines[10005: 11005]:\n",
    "    test_input_text, test_target_text = line.split(' ')\n",
    "    # We use space(' ') as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    test_target_text = ' ' + test_target_text + '\\n'\n",
    "    test_input_texts.append(test_input_text)\n",
    "    test_target_texts.append(test_target_text)\n",
    "    for char in test_input_text:\n",
    "        if char not in test_input_characters:\n",
    "            test_input_characters.add(char)\n",
    "    for char in test_target_text:\n",
    "        if char not in test_target_characters:\n",
    "            test_target_characters.add(char)\n",
    "\n",
    "test_input_characters = sorted(list(test_input_characters))\n",
    "test_target_characters = sorted(list(test_target_characters))\n",
    "test_num_encoder_tokens = len(test_input_characters)\n",
    "test_num_decoder_tokens = len(test_target_characters)\n",
    "test_max_encoder_seq_length = max([len(txt) for txt in test_input_texts])\n",
    "test_max_decoder_seq_length = max([len(txt) for txt in test_target_texts])\n",
    "\n",
    "print('Number of samples:', len(test_input_texts))\n",
    "print('Number of unique input tokens:', test_num_encoder_tokens)\n",
    "print('Number of unique output tokens:', test_num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', test_max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', test_max_decoder_seq_length)\n",
    "\n",
    "test_input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(test_input_characters)])\n",
    "test_target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(test_target_characters)])\n",
    "\n",
    "test_encoder_input_data = np.zeros(\n",
    "    (len(test_input_texts), test_max_encoder_seq_length, test_num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "test_decoder_input_data = np.zeros(\n",
    "    (len(test_input_texts), test_max_decoder_seq_length, test_num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "test_decoder_target_data = np.zeros(\n",
    "    (len(test_input_texts), test_max_decoder_seq_length, test_num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (test_input_text, test_target_text) in enumerate(zip(test_input_texts, test_target_texts)):\n",
    "    for t, char in enumerate(test_input_text):\n",
    "        test_encoder_input_data[i, t, test_input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(test_target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        test_decoder_input_data[i, t, test_target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            test_decoder_target_data[i, t - 1, test_target_token_index[char]] = 1.\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    test_input_seq = test_encoder_input_data[seq_index: seq_index + 1]\n",
    "    print(test_input_seq)\n",
    "    test_decoded_sentence = decode_sequence(test_input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', test_input_texts[seq_index])\n",
    "    print('Decoded sentence:', test_decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer lstm_2 expects 11 inputs, but it received 3 input tensors. Input received: [<tf.Tensor 'input_24:0' shape=(?, ?, 58) dtype=float32>, <tf.Tensor 'input_25:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'input_26:0' shape=(?, 256) dtype=float32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f096f6fddd3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mtest_decoder_states_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_decoder_state_input_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_decoder_state_input_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m test_decoder_outputs, test_state_h, test_state_c = decoder_lstm(\n\u001b[1;32m---> 25\u001b[1;33m     test_decoder_inputs, initial_state=test_decoder_states_inputs)\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mtest_decoder_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_state_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_state_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mtest_decoder_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_decoder_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0moriginal_input_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m             \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m             \u001b[1;31m# with the input_spec set at build time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;31m# Handle mask propagation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    458\u001b[0m                              \u001b[1;34m'but it received '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m                              \u001b[1;34m' input tensors. Input received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m                              str(inputs))\n\u001b[0m\u001b[0;32m    461\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer lstm_2 expects 11 inputs, but it received 3 input tensors. Input received: [<tf.Tensor 'input_24:0' shape=(?, ?, 58) dtype=float32>, <tf.Tensor 'input_25:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'input_26:0' shape=(?, 256) dtype=float32>]"
     ]
    }
   ],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "test_encoder_inputs = Input(shape=(None, test_num_encoder_tokens))\n",
    "test_encoder = LSTM(latent_dim, return_state=True)\n",
    "test_encoder_outputs, test_state_h, test_state_c = test_encoder(test_encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "test_encoder_states = [test_state_h, test_state_c]\n",
    "\n",
    "test_encoder_model = Model(test_encoder_inputs, test_encoder_states)\n",
    "\n",
    "test_decoder_inputs = Input(shape=(None, test_num_decoder_tokens))\n",
    "test_decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "test_decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "test_decoder_states_inputs = [test_decoder_state_input_h, test_decoder_state_input_c]\n",
    "test_decoder_outputs, test_state_h, test_state_c = decoder_lstm(\n",
    "    test_decoder_inputs, initial_state=test_decoder_states_inputs)\n",
    "test_decoder_states = [test_state_h, test_state_c]\n",
    "test_decoder_outputs = decoder_dense(test_decoder_outputs)\n",
    "test_decoder_model = Model(\n",
    "    [test_decoder_inputs] + test_decoder_states_inputs,\n",
    "    [test_decoder_outputs] + test_decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "test_reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in test_input_token_index.items())\n",
    "test_reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in test_target_token_index.items())\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    print(\"before\")\n",
    "    test_states_value = test_encoder_model.predict(input_seq)\n",
    "    print(\"after\")\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    test_target_seq = np.zeros((1, 1, test_num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    test_target_seq[0, 0, test_target_token_index[' ']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    test_decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        test_output_tokens, h, c = test_decoder_model.predict(\n",
    "            [test_target_seq] + test_states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        test_sampled_token_index = np.argmax(test_output_tokens[0, -1, :])\n",
    "        test_sampled_char = test_reverse_target_char_index[test_sampled_token_index]\n",
    "        test_decoded_sentence += test_sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (test_sampled_char == '\\n' or\n",
    "           len(test_decoded_sentence) > test_max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        test_target_seq = np.zeros((1, 1, test_num_decoder_tokens))\n",
    "        test_target_seq[0, 0, test_sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        test_states_value = [h, c]\n",
    "\n",
    "    return test_decoded_sentence\n",
    "\n",
    "    \n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    test_input_seq = test_encoder_input_data[seq_index: seq_index + 1]\n",
    "    print(test_input_seq)\n",
    "    test_decoded_sentence = decode_sequence(test_input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', test_input_texts[seq_index])\n",
    "    print('Decoded sentence:', test_decoded_sentence)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
